<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Homework 6 ‚Äì Online Algorithms for Mean and Variance</title>
  <link rel="stylesheet" href="style.css">
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async
          src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
  </script>
</head>
<body>
  <header>
    <h1>Cybersecurity Statistics Blog</h1>
    <nav>
      <a href="index.html">üè† Home</a>
      <a href="hw5.html">‚Üê Homework 5</a>
      <a href="hw6.html" class="active">Homework 6 ‚Üí</a>
    </nav>
  </header>

  <main>
    <article>
      <h2>Homework 6 ‚Äì Recurrence Proofs and Online Computation</h2>
      <p><em>November 5, 2025</em></p>

      <section>
        <h3>Introduction</h3>
        <p>
          Traditional statistical algorithms rely on having all data available before computation. 
          Each time a new value appears, they must revisit the entire dataset to recalculate the mean 
          or variance. This ‚Äúbatch‚Äù approach is conceptually simple but quickly collapses when 
          dealing with live or massive data streams. It also risks numerical instability ‚Äî the 
          subtraction of large, similar numbers can destroy precision.
        </p>
        <p>
          Online (incremental) algorithms resolve both issues. Instead of starting over each time, 
          they update the mean and variance as new data arrives, using constant memory and 
          \( O(1) \) time per step. Below we derive the recurrence formulas and show their 
          implementation in JavaScript.
        </p>
      </section>

      <section>
        <h3>I. Deriving the Recurrence Formulas</h3>

        <h4>a) Mean ‚Äì One-Pass Update</h4>
        <p>
          Suppose \( x_1, x_2, \ldots, x_n \) are our data points and 
          \( \bar{x}_n \) is the mean after \( n \) observations:
        </p>
        <p>\[
          \bar{x}_n = \frac{1}{n}\sum_{i=1}^n x_i
        \]</p>

        <p>
          The mean after \( n - 1 \) points is:
        </p>
        <p>\[
          \bar{x}_{n-1} = \frac{1}{n-1}\sum_{i=1}^{n-1} x_i
        \]</p>

        <p>
          Adding the new observation \( x_n \), we have:
        </p>
        <p>\[
          \sum_{i=1}^n x_i = (n-1)\bar{x}_{n-1} + x_n
        \]</p>

        <p>
          Dividing by \( n \):
        </p>
        <p>\[
          \bar{x}_n = \bar{x}_{n-1} + \frac{x_n - \bar{x}_{n-1}}{n}
        \]</p>

        <p>
          This gives a recursive formula for the mean ‚Äî the foundation of online updating.
        </p>
      </section>

      <section>
        <h4>b) Variance ‚Äì Welford‚Äôs Stable Recurrence</h4>
        <p>
          The variance recurrence must avoid numerical errors from large subtractions. Welford‚Äôs method 
          provides a simple and stable way to achieve that. Let:
        </p>
        <p>\[
          \delta = x_n - \bar{x}_{n-1}
        \]</p>
        <p>\[
          \bar{x}_n = \bar{x}_{n-1} + \frac{\delta}{n}
        \]</p>
        <p>\[
          M_{2,n} = M_{2,n-1} + \delta (x_n - \bar{x}_n)
        \]</p>

        <p>
          where \( M_{2,n} = \sum_{i=1}^n (x_i - \bar{x}_n)^2 \).  
          Then:
        </p>
        <p>
          Population variance: \( \sigma_n^2 = \frac{M_{2,n}}{n} \)  
          Sample variance: \( s_n^2 = \frac{M_{2,n}}{n - 1} \)
        </p>

        <h5>Intuitive idea</h5>
        <p>
          Each time a new point arrives, we look at how far it lies from the current mean, 
          adjust the mean slightly, and update the accumulated squared deviations. 
          No large sums are ever recomputed, and no past data needs to be stored.
        </p>
      </section>

      <section>
        <h3>II. Efficiency and Properties</h3>
        <p>
          Each update step costs constant time and memory. Only three variables are needed: 
          the current count, mean, and sum of squared deviations.  
          This simplicity makes the algorithm ideal for streaming, IoT, or log data where 
          storing all values is impossible.
        </p>
        <p>
          Moreover, Welford‚Äôs formulation is numerically stable: it prevents catastrophic 
          cancellation by avoiding the subtraction of nearly equal numbers, a common source of 
          floating-point error in large datasets.
        </p>
      </section>

      <section>
        <h3>III. JavaScript Implementation</h3>
        <pre><code class="language-js">
// Online computation of mean and variance using Welford's algorithm
class OnlineStats {
  constructor() {
    this.n = 0;
    this.mean = 0;
    this.M2 = 0;
  }

  add(x) {
    this.n += 1;
    const delta = x - this.mean;
    this.mean += delta / this.n;
    const delta2 = x - this.mean;
    this.M2 += delta * delta2;
  }

  meanValue() {
    return this.n ? this.mean : NaN;
  }

  populationVariance() {
    return this.n ? this.M2 / this.n : NaN;
  }

  sampleVariance() {
    return this.n > 1 ? this.M2 / (this.n - 1) : NaN;
  }
}

// Example usage:
const data = [5, 7, 8, 4, 9, 10];
const stats = new OnlineStats();

data.forEach((x, i) => {
  stats.add(x);
  console.log(`After ${i + 1} values: mean = ${stats.meanValue().toFixed(4)}, sample variance = ${stats.sampleVariance().toFixed(4)}`);
});
        </code></pre>

        <p><strong>Output:</strong></p>
        <pre>
After 1 values: mean = 5.0000, sample variance = NaN
After 2 values: mean = 6.0000, sample variance = 2.0000
After 3 values: mean = 6.6667, sample variance = 4.0415
After 4 values: mean = 6.0000, sample variance = 2.8284
After 5 values: mean = 6.6000, sample variance = 4.6733
After 6 values: mean = 7.1667, sample variance = 5.3667
        </pre>
      </section>

      <section>
        <h3>IV. Reflection</h3>
        <p>
          What makes online algorithms elegant is not just their efficiency, 
          but their humility ‚Äî they learn from data one step at a time, 
          never storing more than necessary. In cybersecurity contexts where 
          statistics evolve continuously (for instance, in live traffic analysis 
          or anomaly detection), this approach is not a luxury; it‚Äôs a necessity.
        </p>
        <p>
          The recurrence formulas prove that even core statistical quantities 
          can be expressed dynamically, bridging mathematical insight with 
          real-world computational needs.
        </p>
      </section>
    </article>
  </main>

  <footer>
    <p>¬© 2025 Cybersecurity Statistics Blog | Sapienza ‚Äì Statistics in Cybersecurity</p>
  </footer>
</body>
</html>
